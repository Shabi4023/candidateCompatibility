{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acaca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import joblib\n",
    "import random\n",
    "from sklearn.utils import shuffle \n",
    "import os\n",
    "import PyPDF2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2afa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Define a function to extract skills from text\n",
    "def extract_skills(text, skills_list):\n",
    "    extracted_skills = []\n",
    "    for skill in skills_list:\n",
    "        if skill.lower() in text.lower():\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "# Create a list of job requirements or skills\n",
    "job_requirements = [\"python\", \"machine learning\", \"data analysis\", \"communication\"]\n",
    "\n",
    "# Create a list of resumes and extract text\n",
    "resume_folder =  r'C:\\Users\\laptop zone\\Downloads\\trainResumes-20230819T080132Z-001\\trainResumes'\n",
    "resumes = []\n",
    "for filename in os.listdir(resume_folder):\n",
    "    if filename.endswith('.pdf'):\n",
    "        resume_text = extract_text_from_pdf(os.path.join(resume_folder, filename))\n",
    "        extracted_skills = extract_skills(resume_text, job_requirements)\n",
    "        resumes.append({'filename': filename, 'text': resume_text, 'skills': extracted_skills})\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "resume_df = pd.DataFrame(resumes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d80b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of labels: 1 for the first 45 rows, 0 for the next 45 rows\n",
    "labels = [1] * 45 + [0] * 45\n",
    "\n",
    "# Assign the labels to the 'fit_for_job' column\n",
    "resume_df['fit_for_job'] = labels\n",
    "\n",
    "\n",
    "# Shuffle the DataFrame to randomize data\n",
    "resume_df = shuffle(resume_df, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# Fit and transform the resume text to TF-IDF vectors\n",
    "X = tfidf_vectorizer.fit_transform(resume_df['text'])\n",
    "\n",
    "# Define the target variable\n",
    "y = resume_df['fit_for_job']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb369ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 50, 'bootstrap': False}\n",
      "Best Accuracy: 72.48%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that your X_train and y_train are in the correct format (dense arrays)\n",
    "X_train_dense = X_train.toarray() if hasattr(X_train, 'toarray') else X_train\n",
    "y_train_dense = y_train.toarray().ravel() if hasattr(y_train, 'toarray') else y_train.ravel()\n",
    "\n",
    "# Define a wider range of hyperparameters for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for cross-validation to handle class imbalances\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search Cross-Validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_classifier, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=100,  # Increase the number of iterations\n",
    "    cv=cv,       # Use StratifiedKFold for cross-validation\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train_dense, y_train_dense)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy: {:.2f}%\".format(random_search.best_score_ * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a4463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best trained model to a file\n",
    "best_rf_model = random_search.best_estimator_\n",
    "joblib.dump(best_rf_model, 'rf_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631b901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64501d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
